{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3eb1c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision.io import read_image\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb04fbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')\n",
    "seed = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc745217",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define custom dataset\n",
    "class CustomDatasetFromCSV(Dataset):\n",
    "    def __init__(self, csv_path, height, width,status,transforms=None):      \n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.labels = np.asarray(self.data.iloc[:, 0])\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.transforms = transforms\n",
    "        self.status = status\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        single_image_label = self.labels[index]        \n",
    "        img_as_np = np.asarray(self.data.iloc[index][self.status:]).reshape(28,28).astype('uint8')\t\n",
    "        img_as_img = Image.fromarray(img_as_np)\n",
    "        \n",
    "        #transform image to tensor\n",
    "        img_as_img = img_as_img.convert('L')    \n",
    "        if self.transforms is not None:\n",
    "            img_as_tensor = self.transforms(img_as_img)       \n",
    "        return (img_as_tensor, single_image_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b93f8659",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create custom dataset\n",
    "transformations = transforms.Compose([transforms.ToTensor()])\n",
    "imageData = CustomDatasetFromCSV('./train.csv',784,784,1,transformations)\n",
    "testData = CustomDatasetFromCSV('./test.csv',784,784,0,transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d0987ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData,validationData=train_test_split(imageData,train_size=0.9,random_state=seed)\n",
    "train_loader = DataLoader(trainData, batch_size = 20)\n",
    "validation_loader = DataLoader(validationData,batch_size=20)\n",
    "test_loader = DataLoader(testData,batch_size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82de5134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis_data_normal=next(iter(train_loader))\n",
    "fig, ax = plt.subplots(2, 2, figsize = (6, 6))\n",
    "for j in range(0,2):\n",
    "    for i in range(0,2):\n",
    "        # ax[i, j].set_title(\"Label: \" + str(vis_data_normal[1][i+(j*2)]), color=\"red\") \n",
    "        ax[i, j].imshow(np.squeeze(vis_data_normal[0][i+(j*2)]), cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ca5dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)  # 4*4 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5a80793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1efae017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.305295  [    0/37800]\n",
      "loss: 1.241775  [ 2000/37800]\n",
      "loss: 0.612065  [ 4000/37800]\n",
      "loss: 0.812499  [ 6000/37800]\n",
      "loss: 0.245854  [ 8000/37800]\n",
      "loss: 0.273763  [10000/37800]\n",
      "loss: 0.210973  [12000/37800]\n",
      "loss: 0.345184  [14000/37800]\n",
      "loss: 0.325439  [16000/37800]\n",
      "loss: 0.226677  [18000/37800]\n",
      "loss: 0.038577  [20000/37800]\n",
      "loss: 0.209177  [22000/37800]\n",
      "loss: 0.069222  [24000/37800]\n",
      "loss: 0.047920  [26000/37800]\n",
      "loss: 0.148361  [28000/37800]\n",
      "loss: 0.034345  [30000/37800]\n",
      "loss: 0.135511  [32000/37800]\n",
      "loss: 0.013564  [34000/37800]\n",
      "loss: 0.084852  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 9.9%, Avg loss: 10.539463 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.038130  [    0/37800]\n",
      "loss: 0.192439  [ 2000/37800]\n",
      "loss: 0.233338  [ 4000/37800]\n",
      "loss: 0.200042  [ 6000/37800]\n",
      "loss: 0.146252  [ 8000/37800]\n",
      "loss: 0.063859  [10000/37800]\n",
      "loss: 0.028124  [12000/37800]\n",
      "loss: 0.089303  [14000/37800]\n",
      "loss: 0.094492  [16000/37800]\n",
      "loss: 0.100090  [18000/37800]\n",
      "loss: 0.011223  [20000/37800]\n",
      "loss: 0.115462  [22000/37800]\n",
      "loss: 0.006226  [24000/37800]\n",
      "loss: 0.008014  [26000/37800]\n",
      "loss: 0.139960  [28000/37800]\n",
      "loss: 0.007447  [30000/37800]\n",
      "loss: 0.023374  [32000/37800]\n",
      "loss: 0.012141  [34000/37800]\n",
      "loss: 0.043947  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 9.9%, Avg loss: 11.676636 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.038654  [    0/37800]\n",
      "loss: 0.015162  [ 2000/37800]\n",
      "loss: 0.130960  [ 4000/37800]\n",
      "loss: 0.261623  [ 6000/37800]\n",
      "loss: 0.067350  [ 8000/37800]\n",
      "loss: 0.045772  [10000/37800]\n",
      "loss: 0.005165  [12000/37800]\n",
      "loss: 0.050987  [14000/37800]\n",
      "loss: 0.063246  [16000/37800]\n",
      "loss: 0.065336  [18000/37800]\n",
      "loss: 0.003338  [20000/37800]\n",
      "loss: 0.102564  [22000/37800]\n",
      "loss: 0.003162  [24000/37800]\n",
      "loss: 0.003098  [26000/37800]\n",
      "loss: 0.196888  [28000/37800]\n",
      "loss: 0.003619  [30000/37800]\n",
      "loss: 0.009070  [32000/37800]\n",
      "loss: 0.008233  [34000/37800]\n",
      "loss: 0.028345  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 9.9%, Avg loss: 12.886012 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.036308  [    0/37800]\n",
      "loss: 0.025124  [ 2000/37800]\n",
      "loss: 0.146480  [ 4000/37800]\n",
      "loss: 0.344381  [ 6000/37800]\n",
      "loss: 0.049917  [ 8000/37800]\n",
      "loss: 0.019937  [10000/37800]\n",
      "loss: 0.003062  [12000/37800]\n",
      "loss: 0.037948  [14000/37800]\n",
      "loss: 0.052079  [16000/37800]\n",
      "loss: 0.028663  [18000/37800]\n",
      "loss: 0.001886  [20000/37800]\n",
      "loss: 0.073902  [22000/37800]\n",
      "loss: 0.001629  [24000/37800]\n",
      "loss: 0.001681  [26000/37800]\n",
      "loss: 0.152081  [28000/37800]\n",
      "loss: 0.001451  [30000/37800]\n",
      "loss: 0.006905  [32000/37800]\n",
      "loss: 0.005542  [34000/37800]\n",
      "loss: 0.028630  [36000/37800]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-af7b5c394956>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtest_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-e2db00cee1d4>\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(dataloader, model, loss_fn)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torchEnv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torchEnv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torchEnv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torchEnv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-56ac1d5a0609>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0msingle_image_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mimg_as_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mimg_as_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_as_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),0.0005)\n",
    "total_step = len(train_loader)\n",
    "epoch = 20\n",
    "model.train()\n",
    "for t in range(epoch):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    test_loop(test_loader, model, loss_fn)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128cb4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.DataFrame(columns=['ImageId','Label'])\n",
    "serial=[]\n",
    "ans=[]\n",
    "model.eval()\n",
    "for s,i in enumerate(test_loader):\n",
    "    serial.append(s+1)\n",
    "    ans.append(((model(i.to(device))).argmax()).to(device))\n",
    "result['ImageId']=serial    \n",
    "result['Label']=np.array(ans)\n",
    "result.to_csv(\"result.csv\",index=False)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d35586b6854ae70032a86b767a712e3a4af1f166395c8db1ad1dec3054479611"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

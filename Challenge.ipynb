{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3eb1c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision.io import read_image\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb04fbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pei/torchEnv/lib/python3.6/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc745217",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define custom dataset\n",
    "class CustomDatasetFromCSV(Dataset):\n",
    "    def __init__(self, csv_path, height, width, transforms=None):      \n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.labels = np.asarray(self.data.iloc[:, 0])\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        single_image_label = self.labels[index]        \n",
    "        img_as_np = np.asarray(self.data.iloc[index][1:]).reshape(28,28).astype('uint8')\t\n",
    "        img_as_img = Image.fromarray(img_as_np)\n",
    "        #transform image to tensor\n",
    "        img_as_img = img_as_img.convert('L')    \n",
    "        if self.transforms is not None:\n",
    "            img_as_tensor = self.transforms(img_as_img)       \n",
    "        return (img_as_tensor, single_image_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b93f8659",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create custom dataset\n",
    "\n",
    "transformations = transforms.Compose([transforms.ToTensor()])\n",
    "imageData = CustomDatasetFromCSV('./train.csv',784,784,transformations)\n",
    "evalSet = CustomDatasetFromCSV('./test.csv',28,784,transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d0987ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "img = imageData[0]\n",
    "print(type(img))\n",
    "train_loader = DataLoader(imageData, batch_size = 20)\n",
    "test_loader = DataLoader(evalSet,batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "251ed38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis_data_normal=next(iter(train_loader))\n",
    "fig, ax = plt.subplots(2, 2, figsize = (6, 6))\n",
    "for j in range(0,2):\n",
    "    for i in range(0,2):\n",
    "        ax[i, j].imshow(np.squeeze(vis_data_normal[0][i+(j*2)]), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ca5dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5a80793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1efae017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.302900  [    0/42000]\n",
      "loss: 1.029743  [ 2000/42000]\n",
      "loss: 0.319282  [ 4000/42000]\n",
      "loss: 0.517389  [ 6000/42000]\n",
      "loss: 0.309072  [ 8000/42000]\n",
      "loss: 0.287071  [10000/42000]\n",
      "loss: 0.203762  [12000/42000]\n",
      "loss: 0.062886  [14000/42000]\n",
      "loss: 0.363805  [16000/42000]\n",
      "loss: 0.157469  [18000/42000]\n",
      "loss: 0.064999  [20000/42000]\n",
      "loss: 0.288898  [22000/42000]\n",
      "loss: 0.049363  [24000/42000]\n",
      "loss: 0.138750  [26000/42000]\n",
      "loss: 0.408269  [28000/42000]\n",
      "loss: 0.358898  [30000/42000]\n",
      "loss: 0.019579  [32000/42000]\n",
      "loss: 0.401185  [34000/42000]\n",
      "loss: 0.231894  [36000/42000]\n",
      "loss: 0.069916  [38000/42000]\n",
      "loss: 0.084049  [40000/42000]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 783 into shape (28,28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-af7b5c394956>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtest_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-e2db00cee1d4>\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(dataloader, model, loss_fn)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torchEnv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torchEnv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torchEnv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torchEnv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-1808514e2df5>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0msingle_image_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mimg_as_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mimg_as_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_as_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#transform image to tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 783 into shape (28,28)"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),0.0005)\n",
    "total_step = len(train_loader)\n",
    "epoch = 20\n",
    "model.train()\n",
    "for t in range(epoch):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    test_loop(test_loader, model, loss_fn)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128cb4af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d35586b6854ae70032a86b767a712e3a4af1f166395c8db1ad1dec3054479611"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f3eb1c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision.io import read_image\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "cb04fbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')\n",
    "seed = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "fc745217",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define custom dataset\n",
    "\n",
    "class CustomDatasetFromCSV(Dataset):\n",
    "    def __init__(self, csv_path, height, width,status,transforms=None):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.labels = np.asarray(self.data.iloc[:, 0])\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.transforms = transforms\n",
    "        self.status = status\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        single_image_label = self.labels[index]        \n",
    "        img_as_np = np.asarray(self.data.iloc[index][self.status:]).reshape(28,28).astype('uint8')\t\n",
    "        \n",
    "        mean_px = np.mean(img_as_np).astype(np.float32)\n",
    "        std_px = np.std(img_as_np).astype(np.float32)\n",
    "        img_as_np = (img_as_np - mean_px)/(std_px)        \n",
    "        \n",
    "        img_as_img = Image.fromarray(img_as_np)\n",
    "        \n",
    "        #transform image to tensor\n",
    "        img_as_img = img_as_img.convert('L')    \n",
    "        if self.transforms is not None:\n",
    "            img_as_tensor = self.transforms(img_as_img)       \n",
    "        return (img_as_tensor, single_image_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b93f8659",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create custom dataset\n",
    "transformations = transforms.Compose([transforms.ToTensor()])\n",
    "imageData = CustomDatasetFromCSV('./train.csv',784,784,1, transformations)\n",
    "#testData = CustomDatasetFromCSV('./test.csv',784,784,0, transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "d42b784c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11.152381\n",
       "7    10.478571\n",
       "3    10.359524\n",
       "9     9.971429\n",
       "2     9.945238\n",
       "6     9.850000\n",
       "0     9.838095\n",
       "4     9.695238\n",
       "8     9.673810\n",
       "5     9.035714\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_data = pd.read_csv('./train.csv')\n",
    "(train_data['label'].value_counts()/len(train_data))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "8d0987ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainData,validationData=train_test_split(imageData,train_size=0.90,random_state=seed)\n",
    "train_loader = DataLoader(trainData, batch_size = 20)\n",
    "validation_loader = DataLoader(validationData,batch_size=20)\n",
    "# test_loader = DataLoader(testData,batch_size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "82de5134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis_data_normal=next(iter(train_loader))\n",
    "fig, ax = plt.subplots(2, 2, figsize = (6, 6))\n",
    "for j in range(0,2):\n",
    "    for i in range(0,2):\n",
    "        # ax[i, j].set_title(\"Label: \" + str(vis_data_normal[1][i+(j*2)]), color=\"red\")\n",
    "        \n",
    "        ax[i, j].imshow(np.squeeze(vis_data_normal[0][i+(j*2)]), cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "0ca5dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv1_bn = nn.BatchNorm2d(6)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv2_bn = nn.BatchNorm2d(16)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)  # 4*4 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "        #self.dropout = nn.Dropout(0.10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.relu(self.conv1_bn(x))\n",
    "        \n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.relu(self.conv2_bn(x))\n",
    "        \n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        #x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "       \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return F.log_softmax(x,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "d5a80793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = F.log_softmax(model(X), dim=1)\n",
    "        loss = loss_fn(pred, y)\n",
    "        #loss = F.nll_loss(pred,y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "1efae017",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.380996  [    0/39900]\n",
      "loss: 0.189956  [ 2000/39900]\n",
      "loss: 0.315386  [ 4000/39900]\n",
      "loss: 0.304280  [ 6000/39900]\n",
      "loss: 0.308563  [ 8000/39900]\n",
      "loss: 0.115913  [10000/39900]\n",
      "loss: 0.348123  [12000/39900]\n",
      "loss: 0.231539  [14000/39900]\n",
      "loss: 0.270275  [16000/39900]\n",
      "loss: 0.118607  [18000/39900]\n",
      "loss: 0.016277  [20000/39900]\n",
      "loss: 0.142487  [22000/39900]\n",
      "loss: 0.030363  [24000/39900]\n",
      "loss: 0.036755  [26000/39900]\n",
      "loss: 0.003752  [28000/39900]\n",
      "loss: 0.026345  [30000/39900]\n",
      "loss: 0.037162  [32000/39900]\n",
      "loss: 0.108977  [34000/39900]\n",
      "loss: 0.295858  [36000/39900]\n",
      "loss: 0.116415  [38000/39900]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.088718 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.028009  [    0/39900]\n",
      "loss: 0.213961  [ 2000/39900]\n",
      "loss: 0.019319  [ 4000/39900]\n",
      "loss: 0.198736  [ 6000/39900]\n",
      "loss: 0.028757  [ 8000/39900]\n",
      "loss: 0.025507  [10000/39900]\n",
      "loss: 0.001486  [12000/39900]\n",
      "loss: 0.261312  [14000/39900]\n",
      "loss: 0.451650  [16000/39900]\n",
      "loss: 0.013837  [18000/39900]\n",
      "loss: 0.006836  [20000/39900]\n",
      "loss: 0.093960  [22000/39900]\n",
      "loss: 0.001284  [24000/39900]\n",
      "loss: 0.023144  [26000/39900]\n",
      "loss: 0.095954  [28000/39900]\n",
      "loss: 0.003023  [30000/39900]\n",
      "loss: 0.052779  [32000/39900]\n",
      "loss: 0.033143  [34000/39900]\n",
      "loss: 0.241126  [36000/39900]\n",
      "loss: 0.050244  [38000/39900]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.081540 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.021366  [    0/39900]\n",
      "loss: 0.060213  [ 2000/39900]\n",
      "loss: 0.033748  [ 4000/39900]\n",
      "loss: 0.145801  [ 6000/39900]\n",
      "loss: 0.104680  [ 8000/39900]\n",
      "loss: 0.042429  [10000/39900]\n",
      "loss: 0.000309  [12000/39900]\n",
      "loss: 0.253147  [14000/39900]\n",
      "loss: 0.027419  [16000/39900]\n",
      "loss: 0.003118  [18000/39900]\n",
      "loss: 0.017446  [20000/39900]\n",
      "loss: 0.004711  [22000/39900]\n",
      "loss: 0.012014  [24000/39900]\n",
      "loss: 0.020355  [26000/39900]\n",
      "loss: 0.023833  [28000/39900]\n",
      "loss: 0.000376  [30000/39900]\n",
      "loss: 0.003643  [32000/39900]\n",
      "loss: 0.018364  [34000/39900]\n",
      "loss: 0.288761  [36000/39900]\n",
      "loss: 0.022371  [38000/39900]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.091176 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.000271  [    0/39900]\n",
      "loss: 0.041056  [ 2000/39900]\n",
      "loss: 0.008605  [ 4000/39900]\n",
      "loss: 0.005095  [ 6000/39900]\n",
      "loss: 0.006209  [ 8000/39900]\n",
      "loss: 0.000441  [10000/39900]\n",
      "loss: 0.000729  [12000/39900]\n",
      "loss: 0.194376  [14000/39900]\n",
      "loss: 0.150771  [16000/39900]\n",
      "loss: 0.001329  [18000/39900]\n",
      "loss: 0.002983  [20000/39900]\n",
      "loss: 0.222104  [22000/39900]\n",
      "loss: 0.020861  [24000/39900]\n",
      "loss: 0.000487  [26000/39900]\n",
      "loss: 0.035114  [28000/39900]\n",
      "loss: 0.000022  [30000/39900]\n",
      "loss: 0.016230  [32000/39900]\n",
      "loss: 0.026792  [34000/39900]\n",
      "loss: 0.407055  [36000/39900]\n",
      "loss: 0.008396  [38000/39900]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.082286 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.000300  [    0/39900]\n",
      "loss: 0.019941  [ 2000/39900]\n",
      "loss: 0.045557  [ 4000/39900]\n",
      "loss: 0.018212  [ 6000/39900]\n",
      "loss: 0.000656  [ 8000/39900]\n",
      "loss: 0.004665  [10000/39900]\n",
      "loss: 0.000026  [12000/39900]\n",
      "loss: 0.073807  [14000/39900]\n",
      "loss: 0.019578  [16000/39900]\n",
      "loss: 0.003078  [18000/39900]\n",
      "loss: 0.001030  [20000/39900]\n",
      "loss: 0.216856  [22000/39900]\n",
      "loss: 0.001108  [24000/39900]\n",
      "loss: 0.002089  [26000/39900]\n",
      "loss: 0.002129  [28000/39900]\n",
      "loss: 0.001452  [30000/39900]\n",
      "loss: 0.000456  [32000/39900]\n",
      "loss: 0.227485  [34000/39900]\n",
      "loss: 0.061608  [36000/39900]\n",
      "loss: 0.009230  [38000/39900]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.075774 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.000088  [    0/39900]\n",
      "loss: 0.004206  [ 2000/39900]\n",
      "loss: 0.015221  [ 4000/39900]\n",
      "loss: 0.082802  [ 6000/39900]\n",
      "loss: 0.011231  [ 8000/39900]\n",
      "loss: 0.000911  [10000/39900]\n",
      "loss: 0.000038  [12000/39900]\n",
      "loss: 0.053328  [14000/39900]\n",
      "loss: 0.338931  [16000/39900]\n",
      "loss: 0.000379  [18000/39900]\n",
      "loss: 0.000245  [20000/39900]\n",
      "loss: 0.032256  [22000/39900]\n",
      "loss: 0.000783  [24000/39900]\n",
      "loss: 0.000846  [26000/39900]\n",
      "loss: 0.001095  [28000/39900]\n",
      "loss: 0.001124  [30000/39900]\n",
      "loss: 0.000055  [32000/39900]\n",
      "loss: 0.027668  [34000/39900]\n",
      "loss: 0.324197  [36000/39900]\n",
      "loss: 0.012107  [38000/39900]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.068474 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.000776  [    0/39900]\n",
      "loss: 0.003770  [ 2000/39900]\n",
      "loss: 0.002957  [ 4000/39900]\n",
      "loss: 0.074661  [ 6000/39900]\n",
      "loss: 0.022086  [ 8000/39900]\n",
      "loss: 0.004915  [10000/39900]\n",
      "loss: 0.009044  [12000/39900]\n",
      "loss: 0.180295  [14000/39900]\n",
      "loss: 0.029992  [16000/39900]\n",
      "loss: 0.000312  [18000/39900]\n",
      "loss: 0.000944  [20000/39900]\n",
      "loss: 0.042348  [22000/39900]\n",
      "loss: 0.000333  [24000/39900]\n",
      "loss: 0.000113  [26000/39900]\n",
      "loss: 0.014948  [28000/39900]\n",
      "loss: 0.000023  [30000/39900]\n",
      "loss: 0.000203  [32000/39900]\n",
      "loss: 0.030120  [34000/39900]\n",
      "loss: 0.027329  [36000/39900]\n",
      "loss: 0.014367  [38000/39900]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.099902 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.006065  [    0/39900]\n",
      "loss: 0.045951  [ 2000/39900]\n",
      "loss: 0.007114  [ 4000/39900]\n",
      "loss: 0.038151  [ 6000/39900]\n",
      "loss: 0.000475  [ 8000/39900]\n",
      "loss: 0.000009  [10000/39900]\n",
      "loss: 0.000038  [12000/39900]\n",
      "loss: 0.137559  [14000/39900]\n",
      "loss: 0.027042  [16000/39900]\n",
      "loss: 0.000522  [18000/39900]\n",
      "loss: 0.000059  [20000/39900]\n",
      "loss: 0.003884  [22000/39900]\n",
      "loss: 0.000641  [24000/39900]\n",
      "loss: 0.000616  [26000/39900]\n",
      "loss: 0.000900  [28000/39900]\n",
      "loss: 0.194673  [30000/39900]\n",
      "loss: 0.005672  [32000/39900]\n",
      "loss: 0.006234  [34000/39900]\n",
      "loss: 0.915402  [36000/39900]\n",
      "loss: 0.006007  [38000/39900]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.078659 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.000100  [    0/39900]\n",
      "loss: 0.002531  [ 2000/39900]\n",
      "loss: 0.009640  [ 4000/39900]\n",
      "loss: 0.081528  [ 6000/39900]\n",
      "loss: 0.000573  [ 8000/39900]\n",
      "loss: 0.000248  [10000/39900]\n",
      "loss: 0.000004  [12000/39900]\n",
      "loss: 0.110919  [14000/39900]\n",
      "loss: 0.094990  [16000/39900]\n",
      "loss: 0.000165  [18000/39900]\n",
      "loss: 0.000473  [20000/39900]\n",
      "loss: 0.012513  [22000/39900]\n",
      "loss: 0.001484  [24000/39900]\n",
      "loss: 0.000818  [26000/39900]\n",
      "loss: 0.115117  [28000/39900]\n",
      "loss: 0.001470  [30000/39900]\n",
      "loss: 0.000467  [32000/39900]\n",
      "loss: 0.006903  [34000/39900]\n",
      "loss: 0.446754  [36000/39900]\n",
      "loss: 0.092349  [38000/39900]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.097870 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.000102  [    0/39900]\n",
      "loss: 0.094494  [ 2000/39900]\n",
      "loss: 0.102845  [ 4000/39900]\n",
      "loss: 0.015734  [ 6000/39900]\n",
      "loss: 0.000103  [ 8000/39900]\n",
      "loss: 0.000227  [10000/39900]\n",
      "loss: 0.000005  [12000/39900]\n",
      "loss: 0.110320  [14000/39900]\n",
      "loss: 0.007603  [16000/39900]\n",
      "loss: 0.044446  [18000/39900]\n",
      "loss: 0.000276  [20000/39900]\n",
      "loss: 0.000395  [22000/39900]\n",
      "loss: 0.000005  [24000/39900]\n",
      "loss: 0.000700  [26000/39900]\n",
      "loss: 0.000054  [28000/39900]\n",
      "loss: 0.000001  [30000/39900]\n",
      "loss: 0.008907  [32000/39900]\n",
      "loss: 0.023249  [34000/39900]\n",
      "loss: 0.152524  [36000/39900]\n",
      "loss: 0.013114  [38000/39900]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.113515 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/39900]\n",
      "loss: 0.000013  [ 2000/39900]\n",
      "loss: 0.004040  [ 4000/39900]\n",
      "loss: 0.030731  [ 6000/39900]\n",
      "loss: 0.002119  [ 8000/39900]\n",
      "loss: 0.001688  [10000/39900]\n",
      "loss: 0.000001  [12000/39900]\n",
      "loss: 0.067730  [14000/39900]\n",
      "loss: 0.007827  [16000/39900]\n",
      "loss: 0.000058  [18000/39900]\n",
      "loss: 0.000050  [20000/39900]\n",
      "loss: 0.000417  [22000/39900]\n",
      "loss: 0.000189  [24000/39900]\n",
      "loss: 0.000157  [26000/39900]\n",
      "loss: 0.000103  [28000/39900]\n",
      "loss: 0.000984  [30000/39900]\n",
      "loss: 0.000005  [32000/39900]\n",
      "loss: 0.022575  [34000/39900]\n",
      "loss: 0.031528  [36000/39900]\n",
      "loss: 0.000053  [38000/39900]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.098966 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/39900]\n",
      "loss: 0.000009  [ 2000/39900]\n",
      "loss: 0.003740  [ 4000/39900]\n",
      "loss: 0.134105  [ 6000/39900]\n",
      "loss: 0.000998  [ 8000/39900]\n",
      "loss: 0.014564  [10000/39900]\n",
      "loss: 0.000002  [12000/39900]\n",
      "loss: 0.101129  [14000/39900]\n",
      "loss: 0.029983  [16000/39900]\n",
      "loss: 0.001508  [18000/39900]\n",
      "loss: 0.000001  [20000/39900]\n",
      "loss: 0.163784  [22000/39900]\n",
      "loss: 0.000015  [24000/39900]\n",
      "loss: 0.053447  [26000/39900]\n",
      "loss: 0.000002  [28000/39900]\n",
      "loss: 0.000006  [30000/39900]\n",
      "loss: 0.000016  [32000/39900]\n",
      "loss: 0.012482  [34000/39900]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.234060  [36000/39900]\n",
      "loss: 0.001147  [38000/39900]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.128241 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/39900]\n",
      "loss: 0.000002  [ 2000/39900]\n",
      "loss: 0.004309  [ 4000/39900]\n",
      "loss: 0.001302  [ 6000/39900]\n",
      "loss: 0.000174  [ 8000/39900]\n",
      "loss: 0.000531  [10000/39900]\n",
      "loss: 0.000002  [12000/39900]\n",
      "loss: 0.087063  [14000/39900]\n",
      "loss: 0.099942  [16000/39900]\n",
      "loss: 0.000138  [18000/39900]\n",
      "loss: 0.000001  [20000/39900]\n",
      "loss: 0.084301  [22000/39900]\n",
      "loss: 0.027367  [24000/39900]\n",
      "loss: 0.001006  [26000/39900]\n",
      "loss: 0.000013  [28000/39900]\n",
      "loss: 0.000001  [30000/39900]\n",
      "loss: 0.000003  [32000/39900]\n",
      "loss: 0.025904  [34000/39900]\n",
      "loss: 0.001344  [36000/39900]\n",
      "loss: 0.000987  [38000/39900]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.155628 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/39900]\n",
      "loss: 0.001549  [ 2000/39900]\n",
      "loss: 0.009409  [ 4000/39900]\n",
      "loss: 0.003010  [ 6000/39900]\n",
      "loss: 0.000594  [ 8000/39900]\n",
      "loss: 0.000030  [10000/39900]\n",
      "loss: 0.000097  [12000/39900]\n",
      "loss: 0.035280  [14000/39900]\n",
      "loss: 0.004299  [16000/39900]\n",
      "loss: 0.001178  [18000/39900]\n",
      "loss: 0.000330  [20000/39900]\n",
      "loss: 0.044934  [22000/39900]\n",
      "loss: 0.000012  [24000/39900]\n",
      "loss: 0.002711  [26000/39900]\n",
      "loss: 0.000001  [28000/39900]\n",
      "loss: 0.000000  [30000/39900]\n",
      "loss: 0.000021  [32000/39900]\n",
      "loss: 0.003061  [34000/39900]\n",
      "loss: 0.060967  [36000/39900]\n",
      "loss: 0.015249  [38000/39900]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.112283 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/39900]\n",
      "loss: 0.001179  [ 2000/39900]\n",
      "loss: 0.000702  [ 4000/39900]\n",
      "loss: 0.314225  [ 6000/39900]\n",
      "loss: 0.000037  [ 8000/39900]\n",
      "loss: 0.037600  [10000/39900]\n",
      "loss: 0.000000  [12000/39900]\n",
      "loss: 0.086351  [14000/39900]\n",
      "loss: 0.124121  [16000/39900]\n",
      "loss: 0.000051  [18000/39900]\n",
      "loss: 0.000001  [20000/39900]\n",
      "loss: 0.000000  [22000/39900]\n",
      "loss: 0.000019  [24000/39900]\n",
      "loss: 0.000014  [26000/39900]\n",
      "loss: 0.000061  [28000/39900]\n",
      "loss: 0.000000  [30000/39900]\n",
      "loss: 0.000045  [32000/39900]\n",
      "loss: 0.000401  [34000/39900]\n",
      "loss: 0.001156  [36000/39900]\n",
      "loss: 0.068967  [38000/39900]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.157262 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),0.005)\n",
    "total_step = len(train_loader)\n",
    "epoch = 15\n",
    "model.train()\n",
    "for t in range(epoch):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    test_loop(validation_loader, model, loss_fn)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "42c94b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "128cb4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pytorch requires a class like this as input to dataloader\n",
    "class DigitDataset(Dataset):\n",
    "    def __init__(self,X):\n",
    "        self.image = X/255 \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image = self.image[idx]\n",
    "        return torch.FloatTensor(image)\n",
    "    \n",
    "\n",
    "test_dir = './test.csv'\n",
    "# load the training data\n",
    "test_data = pd.read_csv(test_dir)\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_data = test_data.reshape(-1,1,28,28)\n",
    "\n",
    "tensor_test = DigitDataset(test_data)\n",
    "\n",
    "test_loader = DataLoader(tensor_test, batch_size = 1)\n",
    "\n",
    "\n",
    "#Load model\n",
    "nn_model = NeuralNetwork()\n",
    "nn_model.load_state_dict(torch.load('./model.pth'))\n",
    "\n",
    "\n",
    "#Function to test the data\n",
    "\n",
    "def test():\n",
    "    \n",
    "    nn_model.eval()\n",
    "    submission = pd.DataFrame(columns=['ImageId','Label'])\n",
    "    id = 1 #It has to start in 1 accordingly to the rules\n",
    "    id_list = []\n",
    "    guess = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader):\n",
    "            \n",
    "            outputs = nn_model(data)\n",
    "            \n",
    "            #Predicts the correct class\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            #print(predicted.item())\n",
    "            \n",
    "            #Rows of the output file\n",
    "            id_list.append(id)\n",
    "            guess.append(predicted.item())\n",
    "            \n",
    "            #Increment for the next id\n",
    "            id+=1\n",
    "            \n",
    "    submission['ImageId'] = id_list\n",
    "    submission['Label'] = guess\n",
    "    \n",
    "    submission.to_csv(\"submission.csv\",index=False)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "30726e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 28000/28000 [00:13<00:00, 2019.25it/s]\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fead7fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d35586b6854ae70032a86b767a712e3a4af1f166395c8db1ad1dec3054479611"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
